

from keras.applications.vgg16 import VGG16
from keras.applications.vgg19 import VGG19
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.vgg16 import preprocess_input
from keras.applications.vgg16 import decode_predictions
from keras import initializers, optimizers, regularizers
from keras.preprocessing.image import ImageDataGenerator
from keras import layers
import tensorflow as tf
import keras.backend as K
from keras.models import Model 

def get_model(_number_classes, _input_shape):
    number_classes = _number_classes   
    model = VGG19(include_top=False, input_shape=_input_shape)
    model = VGG16(include_top=True)
    print(model.summary())

    layer5_out = model.get_layer("block5_pool").output
    layer5_out
    
    layer5a_out = layers.Conv2D(filters=number_classes, 
                                kernel_size=1, 
                                strides=(1, 1), 
                                padding='same', 
                                data_format=None, 
                                dilation_rate=(1, 1), 
                                activation=None,
                                use_bias=True, 
                                kernel_initializer=initializers.random_normal(stddev=0.01),
                                bias_initializer='zeros',
                                kernel_regularizer=regularizers.l2(0.001), 
                                bias_regularizer=None, 
                                activity_regularizer=None, 
                                kernel_constraint=None, 
                                bias_constraint=None)(layer5_out)
    
    layer5a_out
    
    layer3a_in1 = layers.Conv2DTranspose(filters=number_classes, 
                                        kernel_size=4, 
                                        strides=(2, 2), 
                                        padding='same', 
                                        output_padding=None, 
                                        data_format=None, 
                                        dilation_rate=(1, 1), 
                                        activation=None, 
                                        use_bias=True, 
                                        kernel_initializer=initializers.random_normal(stddev=0.01), 
                                        bias_initializer='zeros', 
                                        kernel_regularizer=regularizers.l2(0.001), 
                                        bias_regularizer=None, 
                                        activity_regularizer=None, 
                                        kernel_constraint=None, 
                                        bias_constraint=None)(layer5a_out)
    
    layer3a_in1
    
    layer3_out = model.get_layer("block3_pool").output
    layer3_out.shape
    
    layer3a_in2 = layers.Conv2D(filters=number_classes, 
                                kernel_size=1, 
                                strides=(1, 1), 
                                padding='same', 
                                data_format=None, 
                                dilation_rate=(1, 1), 
                                activation=None,
                                use_bias=True, 
                                kernel_initializer=initializers.random_normal(stddev=0.01),
                                bias_initializer='zeros',
                                kernel_regularizer=regularizers.l2(0.001), 
                                bias_regularizer=None, 
                                activity_regularizer=None, 
                                kernel_constraint=None, 
                                bias_constraint=None)(layer3_out)
    
    layer3a_in2.shape
    
    layer3a_in1.shape
    
    layer4a_out = layers.add([layer3a_in1, layer3a_in2])
    
    
    
    layer2a_in1 = layers.Conv2DTranspose(filters=number_classes, 
                                        kernel_size=4, 
                                        strides=(2, 2), 
                                        padding='same', 
                                        output_padding=None, 
                                        data_format=None, 
                                        dilation_rate=(1, 1), 
                                        activation=None, 
                                        use_bias=True, 
                                        kernel_initializer=initializers.random_normal(stddev=0.01), 
                                        bias_initializer='zeros', 
                                        kernel_regularizer=regularizers.l2(0.001), 
                                        bias_regularizer=None, 
                                        activity_regularizer=None, 
                                        kernel_constraint=None, 
                                        bias_constraint=None)(layer4a_out)
    
    
    layer2_out = model.get_layer("block2_pool").output
    layer_2a_in2 = layers.Conv2D(filters=number_classes, 
                                kernel_size=1, 
                                strides=(1, 1), 
                                padding='same', 
                                data_format=None, 
                                dilation_rate=(1, 1), 
                                activation=None,
                                use_bias=True, 
                                kernel_initializer=initializers.random_normal(stddev=0.01),
                                bias_initializer='zeros',
                                kernel_regularizer=regularizers.l2(0.001), 
                                bias_regularizer=None, 
                                activity_regularizer=None, 
                                kernel_constraint=None, 
                                bias_constraint=None)(layer2_out)
    
    
    layer2a_out = layers.add([layer2a_in1, layer_2a_in2])
    
    nn_last_layer = layers.Conv2DTranspose(filters=number_classes, 
                                        kernel_size=16, 
                                        strides=(8, 8), 
                                        padding='same', 
                                        output_padding=None, 
                                        data_format=None, 
                                        dilation_rate=(1, 1), 
                                        activation=None, 
                                        use_bias=True, 
                                        kernel_initializer=initializers.random_normal(stddev=0.01), 
                                        bias_initializer='zeros', 
                                        kernel_regularizer=regularizers.l2(0.001), 
                                        bias_regularizer=None, 
                                        activity_regularizer=None, 
                                        kernel_constraint=None, 
                                        bias_constraint=None)(layer2a_out)
    
    

    logits = layers.Reshape((-1, number_classes), name='logits')(nn_last_layer)
    correct_label = layers.Input(shape=(None, None, None, number_classes))
    correct_label = layers.Reshape((-1, number_classes), name='correct_labels')(correct_label)
    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= logits,labels= correct_label))
    model_final = Model(input = model.input, output = cross_entropy_loss)
    return model_final



number_classes = 2
input_shape = (2586,2048,3)
model = get_model(number_classes, input_shape)

_optimizer = optimizers.Adam(lr=0.0008, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
model.compile(optimizer=_optimizer,
              loss='categorical_accuracy',
              metrics=['accuracy'])




train_datagen = ImageDataGenerator(
                rescale = 1./255,
                horizontal_flip = True,
                fill_mode = "nearest",
                zoom_range = 0.3,
                width_shift_range = 0.3,
                height_shift_range=0.3,
                rotation_range=30)

train_generator = train_datagen.flow_from_directory(
                train_data_dir,
                target_size = (img_height, img_width),
                batch_size = batch_size, 
                class_mode = "categorical")

#%%



logits = layers.Reshape((-1, number_classes), name='logits')(nn_last_layer)


correct_label = layers.Input(shape=(None, None, None, number_classes))
correct_label = layers.Reshape((-1, number_classes), name='correct_labels')(correct_label)

def mean_pred(logits, correct_label):
    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= logits,labels= correct_label))
    return cross_entropy_loss

_optimizer = optimizers.Adam(lr=0.0008, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
model.compile(optimizer=_optimizer,
              loss='categorical_accuracy',
              metrics=['accuracy', mean_pred])





train_datagen = ImageDataGenerator(
                    rescale = 1./255,
                    horizontal_flip = True,
                    fill_mode = "nearest",
                    zoom_range = 0.3,
                    width_shift_range = 0.3,
                    height_shift_range=0.3,
                    rotation_range=30)


train_generator = train_datagen.flow_from_directory(
                    train_data_dir,
                    target_size = (img_height, img_width),
                    batch_size = batch_size, 
                    class_mode = "categorical")


image = load_img('mug.jpg', target_size=(224, 224))
# convert the image pixels to a numpy array
image = img_to_array(image)






# reshape data for the model
image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
# prepare the image for the VGG model
image = preprocess_input(image)




print(model.summary())


print ''
